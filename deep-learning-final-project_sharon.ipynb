{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8915460,"sourceType":"datasetVersion","datasetId":5361504},{"sourceId":8931161,"sourceType":"datasetVersion","datasetId":5372764}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install networkx matplotlib torch torchvision torch-geometric #praw","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-09T16:06:02.572216Z","iopub.execute_input":"2024-07-09T16:06:02.572507Z","iopub.status.idle":"2024-07-09T16:06:18.431244Z","shell.execute_reply.started":"2024-07-09T16:06:02.572482Z","shell.execute_reply":"2024-07-09T16:06:18.430010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New part reading in the jsons for the network\nimport json\n\nwith open('/kaggle/input/test-network/nx_network_data/gossipcop_fake/gossipcop-1000240645.json') as f:\n    d = json.load(f)\n    print(d)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-07-11T13:33:42.375770Z","iopub.execute_input":"2024-07-11T13:33:42.376269Z","iopub.status.idle":"2024-07-11T13:33:42.390972Z","shell.execute_reply.started":"2024-07-11T13:33:42.376233Z","shell.execute_reply":"2024-07-11T13:33:42.389883Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"{'time': None, 'type': 1, 'user': 3849187751, 'tweet_id': 'gossipcop-1000240645', 'id': 9303106605, 'children': [{'time': 1250565338, 'type': 2, 'user': 4472255223, 'tweet_id': 3375455802, 'id': 7822188508}, {'time': 1259094442, 'type': 2, 'user': 5467375659, 'tweet_id': 6018193721, 'id': 6122009681}, {'time': 1275517044, 'type': 2, 'user': 1305540368, 'tweet_id': 15280521439, 'id': 6151658638}, {'time': 1275517305, 'type': 2, 'user': 9221207372, 'tweet_id': 15280752142, 'id': 6828186223}, {'time': 1275517332, 'type': 2, 'user': 9900119823, 'tweet_id': 15280775581, 'id': 1762054884}, {'time': 1275521267, 'type': 2, 'user': 1652527302, 'tweet_id': 15284376933, 'id': 2873197151}, {'time': 1275523452, 'type': 2, 'user': 1026490347, 'tweet_id': 15286400250, 'id': 7190970843}, {'time': 1275542618, 'type': 2, 'user': 4685921697, 'tweet_id': 15304825948, 'id': 1568679589}, {'time': 1275558831, 'type': 2, 'user': 4685921697, 'tweet_id': 15314917145, 'id': 9903343442}, {'time': 1295791067, 'type': 2, 'user': 2601015361, 'tweet_id': 29175969151451136, 'id': 5577813081}, {'time': 1304600368, 'type': 2, 'user': 5938136634, 'tweet_id': 66124853719207936, 'id': 8013852022}, {'time': 1311672665, 'type': 2, 'user': 6038373039, 'tweet_id': 95788217890111488, 'id': 7135324649}, {'time': 1311672675, 'type': 2, 'user': 2775383736, 'tweet_id': 95788259929620480, 'id': 5974312902}, {'time': 1311674266, 'type': 2, 'user': 6038373039, 'tweet_id': 95794934174597121, 'id': 4218153482}, {'time': 1311678888, 'type': 2, 'user': 4443832005, 'tweet_id': 95814319282982912, 'id': 6443749831, 'children': [{'time': 1315390157, 'type': 3, 'user': 1013573141, 'tweet_id': 111274814680993792, 'id': 7760605448}]}, {'time': 1311679369, 'type': 2, 'user': 6038373039, 'tweet_id': 95816336978092032, 'id': 3202112491}, {'time': 1311682907, 'type': 2, 'user': 6642496644, 'tweet_id': 95831177813954560, 'id': 8489733846}, {'time': 1311683044, 'type': 2, 'user': 5435804114, 'tweet_id': 95831750651019264, 'id': 3579927487}, {'time': 1311711057, 'type': 2, 'user': 6038373039, 'tweet_id': 95949247110844416, 'id': 6117143647}, {'time': 1317780002, 'type': 2, 'user': 1602543119, 'tweet_id': 121404245516886016, 'id': 4025052030}, {'time': 1320603754, 'type': 2, 'user': 5727666441, 'tweet_id': 133247921637433344, 'id': 4933238920}, {'time': 1324231724, 'type': 2, 'user': 5830006596, 'tweet_id': 148464728027561984, 'id': 6767055001}, {'time': 1326679315, 'type': 2, 'user': 5506448509, 'tweet_id': 158730668728270848, 'id': 7702764510}, {'time': 1330170326, 'type': 2, 'user': 3272182385, 'tweet_id': 173373030897160193, 'id': 1992380986}, {'time': 1330403886, 'type': 2, 'user': 6973415356, 'tweet_id': 174352653072084992, 'id': 9134563992}, {'time': 1347244569, 'type': 2, 'user': 3228939077, 'tweet_id': 244987596223160321, 'id': 7131621424}, {'time': 1350423140, 'type': 2, 'user': 9290690020, 'tweet_id': 258319491941928960, 'id': 8094190245}, {'time': 1354633666, 'type': 2, 'user': 6085763123, 'tweet_id': 275979714546511872, 'id': 7879314887}, {'time': 1367840368, 'type': 2, 'user': 3074369148, 'tweet_id': 331372639065088001, 'id': 8583842087}, {'time': 1371533670, 'type': 2, 'user': 8213748666, 'tweet_id': 346863471805202432, 'id': 8414796506}, {'time': 1371541065, 'type': 2, 'user': 9210395365, 'tweet_id': 346894485839552513, 'id': 8226807194}, {'time': 1383229701, 'type': 2, 'user': 2921708685, 'tweet_id': 395920178728697856, 'id': 2495389627}, {'time': 1393826185, 'type': 2, 'user': 7702918077, 'tweet_id': 440365057357389824, 'id': 4736431068}, {'time': 1400959688, 'type': 2, 'user': 4221921471, 'tweet_id': 470285136399843328, 'id': 7733483074}, {'time': 1400960288, 'type': 2, 'user': 5836872084, 'tweet_id': 470287650981572608, 'id': 7579491968}, {'time': 1400963150, 'type': 2, 'user': 5210968057, 'tweet_id': 470299655616479232, 'id': 2581749582}, {'time': 1400964149, 'type': 2, 'user': 5210968057, 'tweet_id': 470303845457723392, 'id': 7879818944}, {'time': 1400964152, 'type': 2, 'user': 5210968057, 'tweet_id': 470303860104253440, 'id': 8854468847}, {'time': 1400964486, 'type': 2, 'user': 4189730260, 'tweet_id': 470305261450588161, 'id': 1596980000}, {'time': 1400969480, 'type': 2, 'user': 5210968057, 'tweet_id': 470326206819078144, 'id': 3883348486}, {'time': 1400979204, 'type': 2, 'user': 4128640947, 'tweet_id': 470366992516390912, 'id': 3675519967}, {'time': 1400979865, 'type': 2, 'user': 5210968057, 'tweet_id': 470369763932114945, 'id': 8714271269}, {'time': 1400990716, 'type': 2, 'user': 5210968057, 'tweet_id': 470415277184667648, 'id': 6620090381, 'children': [{'time': 1401030364, 'type': 3, 'user': 2326497468, 'tweet_id': 470475876950626304, 'id': 6868556642}]}, {'time': 1400992393, 'type': 2, 'user': 7541953005, 'tweet_id': 470422310185230336, 'id': 2846659492}, {'time': 1400997766, 'type': 2, 'user': 6081948039, 'tweet_id': 470444847036243968, 'id': 1253425584}, {'time': 1401009977, 'type': 2, 'user': 9195072141, 'tweet_id': 470496064634490880, 'id': 9389056139}, {'time': 1401012879, 'type': 2, 'user': 5210968057, 'tweet_id': 470508235816857601, 'id': 7627630386}, {'time': 1401024651, 'type': 2, 'user': 5210968057, 'tweet_id': 470557609578082304, 'id': 8964389261}, {'time': 1401033764, 'type': 2, 'user': 5210968057, 'tweet_id': 470595831515455489, 'id': 9335278738}, {'time': 1401034762, 'type': 2, 'user': 5210968057, 'tweet_id': 470600016910749696, 'id': 2275721913}, {'time': 1401045128, 'type': 2, 'user': 5210968057, 'tweet_id': 470643498006216704, 'id': 8601055028}, {'time': 1401066499, 'type': 2, 'user': 5210968057, 'tweet_id': 470733135164895233, 'id': 5492735680}, {'time': 1401078274, 'type': 2, 'user': 5210968057, 'tweet_id': 470782520254926848, 'id': 4859336606}, {'time': 1401078647, 'type': 2, 'user': 5210968057, 'tweet_id': 470784084113752064, 'id': 8091201990}, {'time': 1401088933, 'type': 2, 'user': 5210968057, 'tweet_id': 470827229849452544, 'id': 3124179611}, {'time': 1401099648, 'type': 2, 'user': 5210968057, 'tweet_id': 470872170210394114, 'id': 6061234256}, {'time': 1401109715, 'type': 2, 'user': 5210968057, 'tweet_id': 470914394197467137, 'id': 3386446350}, {'time': 1401121528, 'type': 2, 'user': 5210968057, 'tweet_id': 470963942261395456, 'id': 6349652380}, {'time': 1401122111, 'type': 2, 'user': 5210968057, 'tweet_id': 470966386550767616, 'id': 3677844723}, {'time': 1401128274, 'type': 2, 'user': 5210968057, 'tweet_id': 470992235132358656, 'id': 6062704404}, {'time': 1401131920, 'type': 2, 'user': 5210968057, 'tweet_id': 471007531024654336, 'id': 1893230013}, {'time': 1401132616, 'type': 2, 'user': 5210968057, 'tweet_id': 471010449152946176, 'id': 6465012822}, {'time': 1401138946, 'type': 2, 'user': 5210968057, 'tweet_id': 471036999172767744, 'id': 3164231610}, {'time': 1401139814, 'type': 2, 'user': 5210968057, 'tweet_id': 471040637534355457, 'id': 2701151966}, {'time': 1401149539, 'type': 2, 'user': 5210968057, 'tweet_id': 471081426809409536, 'id': 7107873562}, {'time': 1401160508, 'type': 2, 'user': 5210968057, 'tweet_id': 471127434255806464, 'id': 6235857533}, {'time': 1401165614, 'type': 2, 'user': 5210968057, 'tweet_id': 471148852158816256, 'id': 2509162363}, {'time': 1401176853, 'type': 2, 'user': 5210968057, 'tweet_id': 471195993455620097, 'id': 2705210716}, {'time': 1401188363, 'type': 2, 'user': 5210968057, 'tweet_id': 471244270074998785, 'id': 9866936701}, {'time': 1401192842, 'type': 2, 'user': 5210968057, 'tweet_id': 471263056542978050, 'id': 7909784136}, {'time': 1401194002, 'type': 2, 'user': 5210968057, 'tweet_id': 471267920970932225, 'id': 9319665834}, {'time': 1401205080, 'type': 2, 'user': 5210968057, 'tweet_id': 471314382253600768, 'id': 8847350740}, {'time': 1401211538, 'type': 2, 'user': 5210968057, 'tweet_id': 471341470230671361, 'id': 6810039135}, {'time': 1401221591, 'type': 2, 'user': 5210968057, 'tweet_id': 471383637397499904, 'id': 3040552810}, {'time': 1401223391, 'type': 2, 'user': 5210968057, 'tweet_id': 471391187358605314, 'id': 7430540389}, {'time': 1401224011, 'type': 2, 'user': 5210968057, 'tweet_id': 471393786405195776, 'id': 2838653810}, {'time': 1401235853, 'type': 2, 'user': 5210968057, 'tweet_id': 471443455567081472, 'id': 6698372864}, {'time': 1401247162, 'type': 2, 'user': 5210968057, 'tweet_id': 471490887516565504, 'id': 4131428558}, {'time': 1401256586, 'type': 2, 'user': 5210968057, 'tweet_id': 471530414310322176, 'id': 3891656639}, {'time': 1401258036, 'type': 2, 'user': 5210968057, 'tweet_id': 471536496109842432, 'id': 3690297832}, {'time': 1401268482, 'type': 2, 'user': 5210968057, 'tweet_id': 471580310925099009, 'id': 4850341710}, {'time': 1401277446, 'type': 2, 'user': 5210968057, 'tweet_id': 471617909018488833, 'id': 3673203070}, {'time': 1401278616, 'type': 2, 'user': 5210968057, 'tweet_id': 471622817671155712, 'id': 3064965187}, {'time': 1401297666, 'type': 2, 'user': 5210968057, 'tweet_id': 471702717543354368, 'id': 3852572741}, {'time': 1401391264, 'type': 2, 'user': 5210968057, 'tweet_id': 472095298110496768, 'id': 7522248237}, {'time': 1409906251, 'type': 2, 'user': 8105295073, 'tweet_id': 507809739838083072, 'id': 1709418981}, {'time': 1421243522, 'type': 2, 'user': 1624597418, 'tweet_id': 555361703383564288, 'id': 4533814881}, {'time': 1459275207, 'type': 2, 'user': 7867660663, 'tweet_id': 714878152070209540, 'id': 8857977234}, {'time': 1474560286, 'type': 2, 'user': 3574926720, 'tweet_id': 778988419284242432, 'id': 9968270031}, {'time': 1474576959, 'type': 2, 'user': 7900745840, 'tweet_id': 779058348360474624, 'id': 4564017309}, {'time': 1474591204, 'type': 2, 'user': 2293031070, 'tweet_id': 779118096019820544, 'id': 4517479315, 'children': [{'time': 1474617168, 'type': 3, 'user': 2109922554, 'tweet_id': 779121300589600768, 'id': 8046965554}]}, {'time': 1474622110, 'type': 2, 'user': 2293031070, 'tweet_id': 779247725313396736, 'id': 6412865109}, {'time': 1474623075, 'type': 2, 'user': 9833551455, 'tweet_id': 779251775962427392, 'id': 4055962439}, {'time': 1485111513, 'type': 2, 'user': 9787666284, 'tweet_id': 823243473625067520, 'id': 7970909371, 'children': [{'time': 1485111882, 'type': 4, 'user': 4717079248, 'tweet_id': 823245018358050816, 'id': 9262765751, 'children': [{'time': 1485112067, 'type': 4, 'user': 9787666284, 'tweet_id': 823245795696619520, 'id': 4465121240, 'children': [{'time': 1485112406, 'type': 4, 'user': 4717079248, 'tweet_id': 823247217188278272, 'id': 5447383559, 'children': [{'time': 1485112524, 'type': 4, 'user': 9787666284, 'tweet_id': 823247710845186048, 'id': 9207324733}]}]}]}]}, {'time': 1490170646, 'type': 2, 'user': 8438987673, 'tweet_id': 844463013247766530, 'id': 1774578190}, {'time': 1498330805, 'type': 2, 'user': 8409830341, 'tweet_id': 878689199452442624, 'id': 6089045901}, {'time': 1516765345, 'type': 2, 'user': 8649847957, 'tweet_id': 956009264417472517, 'id': 4608758806}, {'time': 1524522328, 'type': 2, 'user': 2293031070, 'tweet_id': 988544410014101506, 'id': 2350639464}, {'time': 1524524352, 'type': 2, 'user': 6177324249, 'tweet_id': 988552899365044224, 'id': 5932984396}, {'time': 1524538789, 'type': 2, 'user': 6998820966, 'tweet_id': 988613451391127553, 'id': 4982068352}, {'time': 1524538924, 'type': 2, 'user': 4818802827, 'tweet_id': 988614020667191298, 'id': 8760456151}, {'time': 1524542417, 'type': 2, 'user': 2293031070, 'tweet_id': 988628672109215744, 'id': 4795097545}, {'time': 1524546279, 'type': 2, 'user': 9929504391, 'tweet_id': 988644870129639424, 'id': 1392985389, 'children': [{'time': 1524632620, 'type': 4, 'user': 7905518734, 'tweet_id': 989007009918996480, 'id': 8354202688}, {'time': 1524640515, 'type': 4, 'user': 9929504391, 'tweet_id': 989040121902231554, 'id': 2007918253}]}, {'time': 1524573023, 'type': 2, 'user': 2293031070, 'tweet_id': 988757041014542336, 'id': 1540617141}, {'time': 1524589216, 'type': 2, 'user': 2295568327, 'tweet_id': 988824958158757888, 'id': 4893289763}, {'time': 1524592810, 'type': 2, 'user': 8604185180, 'tweet_id': 988840032592113665, 'id': 7203808350}, {'time': 1524668599, 'type': 2, 'user': 1261163916, 'tweet_id': 989157916971282432, 'id': 5623459893}, {'time': 1524782602, 'type': 2, 'user': 5204513245, 'tweet_id': 989636077920104450, 'id': 9057825306}, {'time': 1524782847, 'type': 2, 'user': 5010023873, 'tweet_id': 989637105549705216, 'id': 7864836491}, {'time': 1524782926, 'type': 2, 'user': 8176320467, 'tweet_id': 989637436190920705, 'id': 3976889131}, {'time': 1525909216, 'type': 2, 'user': 2293031070, 'tweet_id': 994361440600576000, 'id': 9168273744}, {'time': 1525910564, 'type': 2, 'user': 7782065808, 'tweet_id': 994367095344369664, 'id': 9160435691}, {'time': 1525933205, 'type': 2, 'user': 2293031070, 'tweet_id': 994462057905967104, 'id': 6880367052, 'children': [{'time': 1525974751, 'type': 3, 'user': 5854399142, 'tweet_id': 994530618687049728, 'id': 4597592164}]}, {'time': 1525933800, 'type': 2, 'user': 6218340737, 'tweet_id': 994464554087153664, 'id': 1239048323, 'children': [{'time': 1525959903, 'type': 3, 'user': 9370870562, 'tweet_id': 994468339907944448, 'id': 8089031136}]}, {'time': 1525945783, 'type': 2, 'user': 6358351233, 'tweet_id': 994514814411067392, 'id': 2757284266}, {'time': 1525961149, 'type': 2, 'user': 6045792857, 'tweet_id': 994579262563794945, 'id': 5759568532}, {'time': 1529084157, 'type': 2, 'user': 1261163916, 'tweet_id': 1007678109389348869, 'id': 7946515840}, {'time': 1532106992, 'type': 2, 'user': 8094062670, 'tweet_id': 1020356796131823616, 'id': 7017763017}]}\n","output_type":"stream"}]},{"cell_type":"code","source":"# old part with reddit data\n\n# import praw\n# import time\n# import pandas as pd\n# import os\n# import json\n\n\n# def create_reddit_instance():\n#     return praw.Reddit(client_id=\"-JHt1Wad_d3bRJqN3bQ8xA\",\n#                        client_secret=\"R9DH0RTUWh_hiLB9HWJiyQGD-Ql4Nw\",\n#                        user_agent=\"Mozilla/5.0 (X11; CrOS x86_64 14816.131.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36\")\n\n\n# def save_progress(data, filename, checkpoint):\n#     # Convert list of comments to JSON string before saving\n#     for post in data:\n#         post['comments'] = json.dumps(post['comments'])\n    \n#     # Save data to CSV\n#     df = pd.DataFrame(data)\n#     df.to_csv(filename, index=False)\n    \n#     # Save checkpoint to a text file\n#     with open(filename + '_checkpoint.txt', 'w') as f:\n#         f.write(checkpoint)\n\n\n# def load_progress(filename):\n#     if os.path.exists(filename):\n#         df = pd.read_csv(filename)\n#         data = df.to_dict('records')\n#         # Convert JSON string back to list of tuples\n#         for post in data:\n#             post['comments'] = json.loads(post['comments'])\n#     else:\n#         data = []\n\n#     checkpoint = load_checkpoint(filename)\n#     return data, checkpoint\n\n\n# def load_checkpoint(filename):\n#     # Load checkpoint from a text file if it exists\n#     if os.path.exists(filename + '_checkpoint.txt'):\n#         with open(filename + '_checkpoint.txt', 'r') as f:\n#             return f.read().strip()\n#     return None\n\n\n# def scrape_subreddit(subreddit, num_posts, filename):\n#     data, last_post_id = load_progress(filename)\n#     posts_scraped = len(data)\n\n#     while posts_scraped < num_posts:\n#         for post in subreddit.hot(limit=100):  # Adjust the limit to a reasonable number for each API call\n#             # Skip posts that were processed in the last run\n#             if last_post_id and post.id <= last_post_id:\n#                 continue\n\n#             # Check if post has at least 5 comments\n#             try:\n#                 post.comments.replace_more(limit=None)\n#             except praw.exceptions.APIException as e:\n#                 if e.error_type == 'RATELIMIT':\n#                     wait_time = int(e.message.split(' ')[-2])\n#                     print(f\"Rate limit hit, sleeping for {wait_time} seconds\")\n#                     time.sleep(wait_time)\n#                     continue\n\n#             if len(post.comments.list()) >= 5:\n#                 post_dict = {\n#                     'post_id': post.id,\n#                     'comments': []\n#                 }\n\n#                 # Collect comments\n#                 for comment in post.comments.list():\n#                     post_dict['comments'].append((comment.id, comment.parent_id, comment.body))\n\n#                 data.append(post_dict)\n#                 posts_scraped += 1\n#                 print(f\"Saved post {posts_scraped}\")\n\n#                 # Save progress every 15 posts\n#                 if posts_scraped % 15 == 0:\n#                     save_progress(data, filename, post.id)\n#                     print(f\"Saved progress to {filename}. Sleeping for 45 seconds to avoid rate limiting...\")\n#                     time.sleep(45)\n\n#                 # Break the inner loop to avoid hitting the limit on fetched posts\n#                 if posts_scraped >= num_posts:\n#                     break\n\n#     save_progress(data, filename, post.id)\n#     return data\n\n\n# # Initialize Reddit instance\n# reddit = create_reddit_instance()\n\n# print(\"Starting to scrape worldnews...\")\n# worldnews_data = scrape_subreddit(reddit.subreddit('worldnews'), 250, '/kaggle/working/worldnews.csv')\n# save_progress(worldnews_data, '/kaggle/working/worldnews.csv', '')\n\n\n# print(\"Starting to scrape fakenews...\")\n# fakenews_data = scrape_subreddit(reddit.subreddit('fakenews'), 250, '/kaggle/working/fakenews.csv')\n# save_progress(fakenews_data, '/kaggle/working/fakenews.csv', '')\n\n\n# print(\"Scraping complete!\")\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-09T14:27:53.072604Z","iopub.execute_input":"2024-07-09T14:27:53.073130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n# import json\n\n# def load_csv_data(filename):\n#     df = pd.read_csv(filename)\n#     data = df.to_dict('records')\n#     cleaned_data = []\n#     for post in data:\n#         try:\n#             post['comments'] = json.loads(post['comments'])\n#             # Ensure comments are in expected format (list of tuples)\n#             if isinstance(post['comments'], list) and all(isinstance(comment, list) and len(comment) == 3 for comment in post['comments']):\n#                 cleaned_data.append(post)\n#             else:\n# #                 print(f\"Unexpected format in comments: {post['comments']}\")\n#         except json.JSONDecodeError as e:\n# #             print(f\"JSON decode error: {e}. Skipping post: {post['post_id']}\")\n#     return cleaned_data\n\n# worldnews_data = load_csv_data('/kaggle/input/reddit-networks/worldnews.csv')\n# fakenews_data = load_csv_data('/kaggle/input/reddit-networks/fakenews.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-09T16:07:07.004859Z","iopub.execute_input":"2024-07-09T16:07:07.005508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(len(fakenews_data))\n# print(len(worldnews_data))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Network creation, need to adjust to work with the new data, will do later\n\nimport networkx as nx\nimport torch\nfrom torch_geometric.data import Data\n\ndef construct_graph(post_data):\n    G = nx.DiGraph()\n    id_map = {}  # mapping from string IDs to integer indices\n    idx = 0\n\n    for comment in post_data['comments']:\n        # Check if comment is already in expected tuple format\n        if isinstance(comment, list) and len(comment) == 3:\n            comment_id, parent_id, _ = comment\n        else:\n            print(f\"Skipping malformed comment: {comment}\")\n            continue\n\n        if comment_id not in id_map:\n            id_map[comment_id] = idx\n            idx += 1\n        if parent_id not in id_map and parent_id != post_data['post_id']:\n            id_map[parent_id] = idx\n            idx += 1\n        \n        G.add_node(id_map[comment_id])\n        if parent_id != post_data['post_id']:  # skip main post\n            G.add_edge(id_map[parent_id], id_map[comment_id])\n    \n    return G\n\nworldnews_graphs = [construct_graph(post) for post in worldnews_data]\nfakenews_graphs = [construct_graph(post) for post in fakenews_data]\n\n\ndef graph_to_data(graph, label):\n    edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n    x = torch.ones((graph.number_of_nodes(), 1), dtype=torch.float)  # feature: all ones\n    y = torch.tensor([label], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y)\n\nworldnews_dataset = [graph_to_data(graph, 0) for graph in worldnews_graphs]\nfakenews_dataset = [graph_to_data(graph, 1) for graph in fakenews_graphs]\ndataset = worldnews_dataset + fakenews_dataset\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import networkx as nx\nimport torch\nfrom torch_geometric.data import Data\nimport json\n\ndef construct_graph(post_data):\n    G = nx.DiGraph()\n    id_map = {}  # mapping from string IDs to integer indices\n    idx = 0\n\n    for comment in post_data['comments']:\n        print(f\"Comment data: {comment}\")  # Debug print\n        # Check if comment is a tuple or a string\n        if isinstance(comment, str):\n            # If it's a string, try to parse it as JSON\n            comment = json.loads(comment)\n        try:\n            comment_id, parent_id, _ = comment\n        except ValueError as e:\n            print(f\"Error unpacking comment: {e}, comment: {comment}\")  # Debug print\n            continue  # Skip the malformed comment\n\n        if comment_id not in id_map:\n            id_map[comment_id] = idx\n            idx += 1\n        if parent_id not in id_map and parent_id != post_data['post_id']:\n            id_map[parent_id] = idx\n            idx += 1\n        \n        G.add_node(id_map[comment_id])\n        if parent_id != post_data['post_id']:  # skip main post\n            G.add_edge(id_map[parent_id], id_map[comment_id])\n    \n    return G\n\nworldnews_graphs = [construct_graph(post) for post in worldnews_data]\nfakenews_graphs = [construct_graph(post) for post in fakenews_data]\n\ndef graph_to_data(graph, label):\n    edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n    x = torch.ones((graph.number_of_nodes(), 1), dtype=torch.float)  # feature: all ones\n    y = torch.tensor([label], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y)\n\nworldnews_dataset = [graph_to_data(graph, 0) for graph in worldnews_graphs]\nfakenews_dataset = [graph_to_data(graph, 1) for graph in fakenews_graphs]\ndataset = worldnews_dataset + fakenews_dataset\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch_geometric.nn import GCNConv, global_mean_pool\nimport torch.nn.functional as F\n\ndef graph_to_data(graph, label):\n    edge_index = torch.tensor(list(graph.edges), dtype=torch.long).t().contiguous()\n    x = torch.ones((graph.number_of_nodes(), 1), dtype=torch.float)  # feature: all ones\n    y = torch.tensor([label], dtype=torch.long)\n    return Data(x=x, edge_index=edge_index, y=y)\n\nworldnews_dataset = [graph_to_data(graph, 0) for graph in worldnews_graphs]\nfakenews_dataset = [graph_to_data(graph, 1) for graph in fakenews_graphs]\ndataset = worldnews_dataset + fakenews_dataset\n\nclass GNN(torch.nn.Module):\n    def __init__(self):\n        super(GNN, self).__init__()\n        self.conv1 = GCNConv(1, 32)\n        self.conv2 = GCNConv(32, 64)\n        self.conv3 = GCNConv(64, 128)\n        self.fc1 = torch.nn.Linear(128, 64)\n        self.fc2 = torch.nn.Linear(64, 2)\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = self.conv2(x, edge_index)\n        x = F.relu(x)\n        x = self.conv3(x, edge_index)\n        x = F.relu(x)\n        x = global_mean_pool(x, data.batch)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch_geometric.loader import DataLoader\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Split the dataset into train, validation, and test sets\ntrain_data, temp_data = train_test_split(dataset, test_size=0.3, random_state=42)\nval_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n\ntrain_loader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = GNN().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n# To track the losses\ntrain_losses = []\nval_losses = []\n\ndef train():\n    model.train()\n    running_loss = 0.0\n    for data in train_loader:\n        data = data.to(device)\n        optimizer.zero_grad()\n        out = model(data)\n        loss = F.nll_loss(out, data.y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * data.num_graphs\n    return running_loss / len(train_loader.dataset)\n\ndef evaluate(loader):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for data in loader:\n            data = data.to(device)\n            out = model(data)\n            loss = F.nll_loss(out, data.y)\n            running_loss += loss.item() * data.num_graphs\n            pred = out.argmax(dim=1)\n            correct += int((pred == data.y).sum())\n            all_preds.append(pred.cpu())\n            all_labels.append(data.y.cpu())\n    return running_loss / len(loader.dataset), correct / len(loader.dataset), torch.cat(all_preds), torch.cat(all_labels)\n\nfor epoch in range(1, 101):\n    train_loss = train()\n    val_loss, val_acc, _, _ = evaluate(val_loader)\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n\n# Plot the training and validation loss\nplt.figure()\nplt.plot(range(1, 101), train_losses, label='Train Loss')\nplt.plot(range(1, 101), val_losses, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate on the test set\ntest_loss, test_acc, test_preds, test_labels = evaluate(test_loader)\nprint(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n\n# Confusion Matrix\ncm = confusion_matrix(test_labels, test_preds)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['World News', 'Fake News'], yticklabels=['World News', 'Fake News'])\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}