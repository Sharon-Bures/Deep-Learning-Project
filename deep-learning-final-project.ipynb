{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8915460,"sourceType":"datasetVersion","datasetId":5361504},{"sourceId":8931161,"sourceType":"datasetVersion","datasetId":5372764}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install networkx matplotlib torch torchvision torch-geometric","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-22T08:05:10.014866Z","iopub.execute_input":"2024-07-22T08:05:10.015241Z","iopub.status.idle":"2024-07-22T08:05:26.167627Z","shell.execute_reply.started":"2024-07-22T08:05:10.015213Z","shell.execute_reply":"2024-07-22T08:05:26.166407Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (3.2.1)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nCollecting torch-geometric\n  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m586.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (4.66.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.11.4)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (3.9.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (1.2.2)\nRequirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.10/site-packages (from torch-geometric) (5.9.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->torch-geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.2.0)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.5.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport os\nimport networkx as nx\nimport torch\nfrom torch_geometric.utils import from_networkx\nfrom torch_geometric.data import Data, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\nfrom torch.utils.data import random_split\n\n\n# function to load json\ndef load_json(file_path):\n    with open(file_path, 'r') as file:\n        data = json.load(file)\n    return data\n\n# make graph\ndef build_graph(data):\n    G = nx.DiGraph()\n    \n    # add  root tweet\n    root_id = data['id']\n    G.add_node(root_id, **data)\n    \n    # recursive function to add children\n    def add_children(children, parent_id):\n        for child in children:\n            G.add_node(child['id'], **child)\n            G.add_edge(parent_id, child['id'])\n            if 'children' in child:\n                add_children(child['children'], child['id'])\n    \n    if 'children' in data:\n        add_children(data['children'], root_id)\n    \n    return G\n\n\n\n# function to normalize node attributes\ndef normalize_node_attributes(graph):\n    all_attributes = set()\n    for _, attrs in graph.nodes(data=True):\n        all_attributes.update(attrs.keys())\n\n    for node, attrs in graph.nodes(data=True):\n        for attr in all_attributes:\n            if attr not in attrs:\n                attrs[attr] = None\n                \n    return graph\n\n\ndef convert_to_data(graph, label):\n    data = from_networkx(graph)\n    \n    # check all nodes have feature vectors, initialize with default feature if not present\n    if not hasattr(data, 'x') or data.x is None:\n        num_nodes = data.num_nodes\n        # initialize with example feature (all ones)\n        data.x = torch.ones((num_nodes, 1))\n    \n    # add labels to all nodes\n    data.y = torch.tensor([label] * data.num_nodes, dtype=torch.long)\n    \n    return data\n\n# eventually would be better to take them out of folder programmatically instead of hand-writing\n# json_dict = {\"gossipcop_fake/gossipcop-1000240645.json\": \"fake\", \n#             \"gossipcop_fake/gossipcop-1000908841.json\": 'fake', \n#             \"gossipcop_fake/gossipcop-1012123555.json\": 'fake',\n#             \"gossipcop_fake/gossipcop-1014383679.json\": 'fake', \n#             \"gossipcop_fake/gossipcop-1014616559.json\": 'fake', \n#             \"gossipcop_real/gossipcop-541230.json\": 'real', \n#             \"gossipcop_real/gossipcop-561182.json\": 'real', \n#             'gossipcop_real/gossipcop-567233.json': 'real', \n#             'gossipcop_real/gossipcop-679264.json': 'real', \n#             'gossipcop_real/gossipcop-681826.json': 'real'\n#             }\n\npath = '/kaggle/input/test-network/nx_network_data/' # change to individual path\n\n\ndef create_json_dict(base_path):\n    json_dict = {}\n    \n    for label in ['gossipcop_fake', 'gossipcop_real']:\n        folder_path = os.path.join(base_path, label)\n        files = os.listdir(folder_path)\n        files = [f for f in files if f.endswith('.json')]\n        for file in files[:10]:  # take the first 10 files, increase to as much as colab/kaggle can handle\n            json_dict[os.path.join(label, file)] = 'fake' if label == 'gossipcop_fake' else 'real'\n    \n    return json_dict\n\njson_dict = create_json_dict(path)\n\nfull_dataset = []\n\n# loop to create mega dataset\nfor dataset in list(json_dict.keys()):\n    file = load_json(path + dataset)\n    graph = normalize_node_attributes(build_graph(file))\n    data = convert_to_data(graph, 1) if json_dict[dataset] == 'fake' else convert_to_data(graph, 0)\n    full_dataset.append(data)\n\nprint(full_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T08:05:26.169504Z","iopub.execute_input":"2024-07-22T08:05:26.169816Z","iopub.status.idle":"2024-07-22T08:05:34.610438Z","shell.execute_reply.started":"2024-07-22T08:05:26.169789Z","shell.execute_reply":"2024-07-22T08:05:34.609474Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[Data(edge_index=[2, 28], time=[29], type=[29], user=[29], tweet_id=[29], id=[29], children=[29], num_nodes=29, x=[29, 1], y=[29]), Data(edge_index=[2, 2], time=[3], type=[3], user=[3], tweet_id=[3], id=[3], children=[3], num_nodes=3, x=[3, 1], y=[3]), Data(edge_index=[2, 15], time=[16], type=[16], user=[16], tweet_id=[16], id=[16], children=[16], num_nodes=16, x=[16, 1], y=[16]), Data(edge_index=[2, 13], time=[14], type=[14], user=[14], tweet_id=[14], id=[14], children=[14], num_nodes=14, x=[14, 1], y=[14]), Data(edge_index=[2, 6], time=[7], type=[7], user=[7], tweet_id=[7], id=[7], children=[7], num_nodes=7, x=[7, 1], y=[7]), Data(edge_index=[2, 15], time=[16], type=[16], user=[16], tweet_id=[16], id=[16], children=[16], num_nodes=16, x=[16, 1], y=[16]), Data(edge_index=[2, 46], time=[47], type=[47], user=[47], tweet_id=[47], id=[47], children=[47], num_nodes=47, x=[47, 1], y=[47]), Data(edge_index=[2, 41], time=[42], type=[42], user=[42], tweet_id=[42], id=[42], children=[42], num_nodes=42, x=[42, 1], y=[42]), Data(edge_index=[2, 118], time=[119], type=[119], user=[119], tweet_id=[119], id=[119], children=[119], num_nodes=119, x=[119, 1], y=[119]), Data(edge_index=[2, 2533], time=[2534], type=[2534], user=[2534], tweet_id=[2534], id=[2534], children=[2534], num_nodes=2534, x=[2534, 1], y=[2534]), Data(edge_index=[2, 42], time=[43], type=[43], user=[43], tweet_id=[43], id=[43], children=[43], num_nodes=43, x=[43, 1], y=[43]), Data(edge_index=[2, 99], time=[100], type=[100], user=[100], tweet_id=[100], id=[100], children=[100], num_nodes=100, x=[100, 1], y=[100]), Data(edge_index=[2, 53], time=[54], type=[54], user=[54], tweet_id=[54], id=[54], children=[54], num_nodes=54, x=[54, 1], y=[54]), Data(edge_index=[2, 84], time=[85], type=[85], user=[85], tweet_id=[85], id=[85], children=[85], num_nodes=85, x=[85, 1], y=[85]), Data(edge_index=[2, 79], time=[80], type=[80], user=[80], tweet_id=[80], id=[80], children=[80], num_nodes=80, x=[80, 1], y=[80]), Data(edge_index=[2, 77], time=[78], type=[78], user=[78], tweet_id=[78], id=[78], children=[78], num_nodes=78, x=[78, 1], y=[78]), Data(edge_index=[2, 54], time=[55], type=[55], user=[55], tweet_id=[55], id=[55], children=[55], num_nodes=55, x=[55, 1], y=[55]), Data(edge_index=[2, 65], time=[66], type=[66], user=[66], tweet_id=[66], id=[66], children=[66], num_nodes=66, x=[66, 1], y=[66]), Data(edge_index=[2, 26], time=[27], type=[27], user=[27], tweet_id=[27], id=[27], children=[27], num_nodes=27, x=[27, 1], y=[27]), Data(edge_index=[2, 57], time=[58], type=[58], user=[58], tweet_id=[58], id=[58], children=[58], num_nodes=58, x=[58, 1], y=[58])]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split the dataset into training, validation, and test sets\ntrain_size = int(0.7 * len(dataset))\nval_size = int(0.15 * len(dataset))\ntest_size = len(dataset) - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n\n# Create DataLoaders for each set\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n\nclass GNN(nn.Module):\n    def __init__(self, num_node_features):\n        super(GNN, self).__init__()\n        self.conv1 = GCNConv(num_node_features, 16)\n        self.conv2 = GCNConv(16, 2)\n    \n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        \n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = self.conv2(x, edge_index)\n        \n        return F.log_softmax(x, dim=1)\n\n# Initialize the model, optimizer, and loss function\nnum_node_features = 1  # Assuming each node has one feature, adjust based on your data\nmodel = GNN(num_node_features)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\nloss_fn = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:45:01.139461Z","iopub.execute_input":"2024-07-20T14:45:01.139843Z","iopub.status.idle":"2024-07-20T14:45:01.152943Z","shell.execute_reply.started":"2024-07-20T14:45:01.139814Z","shell.execute_reply":"2024-07-20T14:45:01.151980Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# Training loop\ndef train(loader):\n    model.train()\n    total_loss = 0\n    for data in loader:\n        optimizer.zero_grad()\n        out = model(data)\n        loss = loss_fn(out, data.y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(loader)\n\n# Evaluation function\ndef test(loader):\n    model.eval()\n    correct = 0\n    for data in loader:\n        with torch.no_grad():\n            out = model(data)\n            pred = out.argmax(dim=1)\n            correct += (pred == data.y).sum().item()\n    return correct / sum([data.num_nodes for data in loader.dataset])\n\n# Training the model\nfor epoch in range(200):\n    train_loss = train(train_loader)\n    val_accuracy = test(val_loader)\n    print(f'Epoch {epoch}, Loss: {train_loss}, Validation Accuracy: {val_accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-07-20T14:45:44.203664Z","iopub.execute_input":"2024-07-20T14:45:44.204544Z","iopub.status.idle":"2024-07-20T14:45:44.319021Z","shell.execute_reply.started":"2024-07-20T14:45:44.204510Z","shell.execute_reply":"2024-07-20T14:45:44.317849Z"},"trusted":true},"execution_count":56,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[56], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m---> 27\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     val_accuracy \u001b[38;5;241m=\u001b[39m test(val_loader)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[56], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(out, data\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[54], line 20\u001b[0m, in \u001b[0;36mGNN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m---> 20\u001b[0m     x, edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m, data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index)\n\u001b[1;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'x'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'x'","output_type":"error"}]}]}